# Configuración del Core Cognitivo

core:
  name: "CognitiveCore"
  description: "Sistema multi-agente genérico basado en Google ADK y protocolo A2A"
  version: "1.0.0"
  default_model: "gemini-2.0-flash"
  log_level: "INFO"
  
  # Configuración de GCP
  gcp:
    project_id: "${GCP_PROJECT_ID}"
    location: "us-central1"
    credentials_path: "${GOOGLE_APPLICATION_CREDENTIALS}"
  
  # Configuración de ADK
  adk:
    session_service: "InMemorySessionService"  # o VertexAiSessionService
    enable_tracing: true
    enable_logging: true
  
  # Configuración de A2A
  a2a:
    enable_discovery: true
    discovery_timeout: 30
    max_agents: 100
  
  # Configuración del pipeline
  pipeline:
    document_processing: true
    image_processing: true
    structured_data_processing: true
    unstructured_data_processing: true
  
  # Configuración de orquestación
  orchestration:
    default_strategy: "sequential"
    max_parallel_agents: 5
    timeout_seconds: 300
  
  # Configuración de síntesis de conocimiento
  knowledge_synthesis:
    enable_pattern_detection: true
    enable_conflict_detection: true
    confidence_threshold: 0.7
  
  # Configuración de decisiones
  decision_engine:
    enable_reasoning: true
    enable_explanation: true
    max_reasoning_steps: 10

# Configuración de modelos
models:
  gemini-2.0-flash:
    display_name: "Gemini 2.0 Flash"
    description: "Modelo rápido y eficiente para tareas generales"
    llm_model: "gemini-2.0-flash"
    capabilities: ["text", "reasoning"]
    max_tokens: 8192
    temperature: 0.7
  
  gemini-2.0-pro:
    display_name: "Gemini 2.0 Pro"
    description: "Modelo avanzado para tareas complejas"
    llm_model: "gemini-2.0-pro"
    capabilities: ["text", "reasoning", "vision", "audio"]
    max_tokens: 32768
    temperature: 0.3
  
  gemini-1.5-flash:
    display_name: "Gemini 1.5 Flash"
    description: "Modelo rápido con contexto extendido"
    llm_model: "gemini-1.5-flash"
    capabilities: ["text", "reasoning", "vision"]
    max_tokens: 8192
    temperature: 0.7